import streamlit as st
from openai import OpenAI

# -------------------------------
# 4. ChatPDF í˜ì´ì§€
# -------------------------------

st.title("4. ChatPDF - PDFë¡œ ëŒ€í™”í•˜ê¸°")

# --- API Key ì²˜ë¦¬ (ë‹¤ë¥¸ í˜ì´ì§€ì™€ ë™ì¼í•œ ë°©ì‹) ---
if "api_key" not in st.session_state:
    st.session_state.api_key = ""

api_key_input = st.text_input(
    "OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš” (í•„ìš”ì‹œ ë‹¤ì‹œ ì…ë ¥)",
    type="password",
    value=st.session_state.api_key,
)

if api_key_input and api_key_input != st.session_state.api_key:
    st.session_state.api_key = api_key_input

if not st.session_state.api_key:
    st.warning("ë¨¼ì € API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

client = OpenAI(api_key=st.session_state.api_key)

# --- Vector Store & ìƒíƒœ ë³€ìˆ˜ë“¤ ---
if "vector_store_id" not in st.session_state:
    st.session_state.vector_store_id = None

if "uploaded_pdf_name" not in st.session_state:
    st.session_state.uploaded_pdf_name = None

if "pdf_chat_history" not in st.session_state:
    # [{"role": "user"/"assistant", "content": "..."}...]
    st.session_state.pdf_chat_history = []

# -------------------------------
# 1) PDF ì—…ë¡œë“œ ì˜ì—­ (í•­ìƒ ë§¨ ìœ„ì— ë³´ì´ë„ë¡)
# -------------------------------
st.markdown("### 1) PDF íŒŒì¼ ì—…ë¡œë“œ")

uploaded_file = st.file_uploader(
    "ë¶„ì„í•  PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (í•œ ê°œë§Œ)",
    type=["pdf"],
)

col1, col2 = st.columns(2)
with col1:
    create_vs = st.button("ğŸ“¥ Vector Store ìƒì„±/ê°±ì‹ ", use_container_width=True)
with col2:
    clear_vs = st.button("ğŸ§¹ Vector Store ì‚­ì œ", use_container_width=True)

# --- Vector Store ìƒì„±/ê°±ì‹  ---
if create_vs:
    if not uploaded_file:
        st.warning("ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        with st.spinner("Vector Store ìƒì„± ì¤‘... (PDF ì„ë² ë”© ì¤‘ì…ë‹ˆë‹¤)"):
            # ìƒˆ Vector Store ìƒì„±
            vs = client.vector_stores.create(name="chatpdf_vector_store")

            # ì—…ë¡œë“œí•œ PDFë¥¼ Vector Storeì— ë“±ë¡
            file_batch = client.vector_stores.file_batches.upload_and_poll(
                vector_store_id=vs.id,
                files=[uploaded_file],
            )

            st.session_state.vector_store_id = vs.id
            st.session_state.uploaded_pdf_name = uploaded_file.name
            st.session_state.pdf_chat_history = []  # ìƒˆ íŒŒì¼ì´ë©´ ëŒ€í™”ë„ ì´ˆê¸°í™”

        st.success(f"Vector Store ìƒì„± ì™„ë£Œ! (íŒŒì¼: {uploaded_file.name})")

# --- Vector Store ì‚­ì œ ---
if clear_vs and st.session_state.vector_store_id is not None:
    with st.spinner("Vector Store ì‚­ì œ ì¤‘..."):
        client.vector_stores.delete(st.session_state.vector_store_id)

    st.session_state.vector_store_id = None
    st.session_state.uploaded_pdf_name = None
    st.session_state.pdf_chat_history = []

    st.success("Vector Storeê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

# --- í˜„ì¬ ìƒíƒœ í‘œì‹œ ---
if st.session_state.vector_store_id:
    st.info(
        f"ğŸ“„ í˜„ì¬ Vector Store ì‚¬ìš© ì¤‘\n\n"
        f"- ID: `{st.session_state.vector_store_id}`\n"
        f"- íŒŒì¼ ì´ë¦„: **{st.session_state.uploaded_pdf_name}**"
    )
else:
    st.info("í˜„ì¬ í™œì„±í™”ëœ Vector Storeê°€ ì—†ìŠµë‹ˆë‹¤. PDFë¥¼ ì—…ë¡œë“œí•˜ê³  'Vector Store ìƒì„±/ê°±ì‹ ' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

st.markdown("---")

# -------------------------------
# 2) PDF ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ (ì±—ë´‡ UI)
# -------------------------------
st.markdown("### 2) PDF ë‚´ìš©ìœ¼ë¡œ ì§ˆì˜ì‘ë‹µ")

# ì´ì „ ëŒ€í™” ë³´ì—¬ì£¼ê¸°
for msg in st.session_state.pdf_chat_history:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# ì±„íŒ… ì…ë ¥ì°½ (í•­ìƒ ë§¨ ì•„ë˜)
user_q = st.chat_input("ì—…ë¡œë“œí•œ PDF ë‚´ìš©ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì„ ì§ˆë¬¸í•´ ë³´ì„¸ìš”.")

if user_q:
    if not st.session_state.vector_store_id:
        st.warning("ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•˜ê³  Vector Storeë¥¼ ìƒì„±í•˜ì„¸ìš”.")
    else:
        # ìœ ì € ë©”ì‹œì§€ ì €ì¥/í‘œì‹œ
        st.session_state.pdf_chat_history.append({"role": "user", "content": user_q})
        with st.chat_message("user"):
            st.write(user_q)

        with st.chat_message("assistant"):
            with st.spinner("PDF ë‚´ìš©ì„ ê²€ìƒ‰í•˜ê³  ë‹µë³€ ì‘ì„± ì¤‘..."):
                response = client.responses.create(
                    model="gpt-5-mini",
                    input=[
                        {
                            "role": "system",
                            "content": (
                                "ë„ˆëŠ” ì—…ë¡œë“œëœ PDF íŒŒì¼ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œë§Œ ë‹µë³€í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤. "
                                "ëª¨ë¥´ê² ê±°ë‚˜ PDFì— ì—†ëŠ” ë‚´ìš©ì´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•´."
                            ),
                        },
                        {
                            "role": "user",
                            "content": user_q,
                        },
                    ],
                    tools=[
                        {
                            "type": "file_search",
                            "vector_store_ids": [st.session_state.vector_store_id],
                            "max_num_results": 10,
                        }
                    ],
                )

                answer = response.output_text
                st.write(answer)

        st.session_state.pdf_chat_history.append(
            {"r
